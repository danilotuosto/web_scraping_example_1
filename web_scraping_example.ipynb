{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WebScraping Example by @danilotuosto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **STEP 1.** Let's import the needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **STEP 2.** Now we're going to assign to a variable named 'link', the desired url through the *get* function from the *requests* package. Next, we're going to check if the url works with *status_code*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = rq.get('https://realpython.github.io/fake-jobs/')\n",
    "link.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **STEP 3.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# We're going to create a BeautifulSoup object to hold only the content of the link variable.\n",
    "soup = bs(link.content, \"html.parser\")\n",
    "\n",
    "# Since soup it's a BeautifulSoup object we can use the bs function find to look for an element\n",
    "# in the html file whose id is equal to ResultsContainer (a div we found in the original web page).\n",
    "results = soup.find(id = 'ResultsContainer')\n",
    "\n",
    "# Now, we'll assign to a list called job_elements all the findings in the web page whose is a div\n",
    "# and, simultanously, its class is card-content.\n",
    "job_elements = results.find_all('div', class_ = 'card-content')\n",
    "\n",
    "# We create a list for each field of the job.\n",
    "title_list, sub_list, loc_list = [], [], []\n",
    "\n",
    "# Though a for cicle we scan for each element in the job_elements' list.\n",
    "for job_element in job_elements:\n",
    "# In each element, we're use the find function to find title, subtitle and location of each job, convert\n",
    "# it to text, and then add it to the list with append.\n",
    "    title = job_element.find('h2', class_ = 'title').text\n",
    "    title_list.append(title)\n",
    "    subtitle = job_element.find('h3', class_ = 'subtitle').text\n",
    "    sub_list.append(subtitle)\n",
    "    loc = job_element.find('p', class_ = 'location').text\n",
    "    loc_list.append(loc)\n",
    "\n",
    "# We're creating a dictoniary to hold these three lists.\n",
    "tab = {\n",
    "    'title': title_list,\n",
    "    'company': sub_list,\n",
    "    'location': loc_list\n",
    "}\n",
    "\n",
    "# Check lists' lenghts\n",
    "print(len(title_list))\n",
    "print(len(sub_list))\n",
    "print(len(loc_list))\n",
    "\n",
    "# Since the three lists don't always have the same length, pandas won't be able to create a DataFrame. \n",
    "# So, we're going to add null values how many times is the difference between the lists' length\n",
    "loc_list += (len(title_list)-len(loc_list)) * [None]\n",
    "\n",
    "# We assign to df the DataFrame containing the tab dictionary.\n",
    "df = pd.DataFrame(tab)\n",
    "\n",
    "# Save it into a csv file\n",
    "df.to_csv('data_scrape', index= False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas, we're going to remove \\n (newline) from all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Python Developer</td>\n",
       "      <td>Payne, Roberts and Davis</td>\n",
       "      <td>Stewartbury, AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Energy engineer</td>\n",
       "      <td>Vasquez-Davidson</td>\n",
       "      <td>Christopherville, AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legal executive</td>\n",
       "      <td>Jackson, Chambers and Levy</td>\n",
       "      <td>Port Ericaburgh, AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fitness centre manager</td>\n",
       "      <td>Savage-Bradley</td>\n",
       "      <td>East Seanview, AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product manager</td>\n",
       "      <td>Ramirez Inc</td>\n",
       "      <td>North Jamieview, AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Museum/gallery exhibitions officer</td>\n",
       "      <td>Nguyen, Yoder and Petty</td>\n",
       "      <td>Lake Abigail, AE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Radiographer, diagnostic</td>\n",
       "      <td>Holder LLC</td>\n",
       "      <td>Jacobshire, AP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Database administrator</td>\n",
       "      <td>Yates-Ferguson</td>\n",
       "      <td>Port Susan, AE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Furniture designer</td>\n",
       "      <td>Ortega-Lawrence</td>\n",
       "      <td>North Tiffany, AA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ship broker</td>\n",
       "      <td>Fuentes, Walls and Castro</td>\n",
       "      <td>Michelleville, AP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title                     company  \\\n",
       "0              Senior Python Developer    Payne, Roberts and Davis   \n",
       "1                      Energy engineer            Vasquez-Davidson   \n",
       "2                      Legal executive  Jackson, Chambers and Levy   \n",
       "3               Fitness centre manager              Savage-Bradley   \n",
       "4                      Product manager                 Ramirez Inc   \n",
       "..                                 ...                         ...   \n",
       "95  Museum/gallery exhibitions officer     Nguyen, Yoder and Petty   \n",
       "96            Radiographer, diagnostic                  Holder LLC   \n",
       "97              Database administrator              Yates-Ferguson   \n",
       "98                  Furniture designer             Ortega-Lawrence   \n",
       "99                         Ship broker   Fuentes, Walls and Castro   \n",
       "\n",
       "                              location  \n",
       "0                Stewartbury, AA        \n",
       "1           Christopherville, AA        \n",
       "2            Port Ericaburgh, AA        \n",
       "3              East Seanview, AP        \n",
       "4            North Jamieview, AP        \n",
       "..                                 ...  \n",
       "95              Lake Abigail, AE        \n",
       "96                Jacobshire, AP        \n",
       "97                Port Susan, AE        \n",
       "98             North Tiffany, AA        \n",
       "99             Michelleville, AP        \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.replace(r'\\n', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('trimmed_data_scrape', index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
